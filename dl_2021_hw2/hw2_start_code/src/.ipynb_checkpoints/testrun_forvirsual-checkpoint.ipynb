{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import data\n",
    "import models\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "argmap = { 'model':'A' ,\n",
    "          'train_path':'os.path.join(data_dir, \\'2-Medium-Scale\\', \\'train\\')' ,\n",
    "          'valid_path':'os.path.join(data_dir,\\'test2\\')' ,\n",
    "          'trainlim':10000000 ,\n",
    "          'validlim':10000000 ,\n",
    "          'batch_size':1 ,\n",
    "          'lr':0.001 ,\n",
    "          'epochs':1 , \n",
    "          'who':'Simply_test' , \n",
    "          'rounds_per_train':1 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../hw2_dataset/\" ## You need to specify the data_dir first\n",
    "inupt_size = 224\n",
    "batch_size = argmap['batch_size']\n",
    "train_loader, valid_loader = data.load_data(data_dir=data_dir,input_size=inupt_size, batch_size=batch_size, argmap=argmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.model_A(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"Task1_modelResnet_best_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from torchvision import models\n",
    "# # l1 = []\n",
    "# l2 = []\n",
    "# # for m in dir(models.vgg16(pretrained=True)):\n",
    "# #     if m[0]!='_': l1.append(m)\n",
    "# for m in dir(models.resnet50(pretrained=True)):\n",
    "#     if m[0]!='_': l2.append(m)\n",
    "# # print(l1)\n",
    "# print(l2)\n",
    "\n",
    "# ['add_module', 'apply', 'avgpool', 'base_width', 'bn1', 'buffers', \n",
    "#  'children', 'conv1', 'cpu', 'cuda', 'dilation', 'double', \n",
    "#  'dump_patches', 'eval', 'extra_repr', 'fc', 'float', 'forward', \n",
    "#  'groups', 'half', 'inplanes', 'layer1', 'layer2', 'layer3', 'layer4', \n",
    "#  'load_state_dict', 'maxpool', 'modules', 'named_buffers', 'named_children', \n",
    "#  'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', \n",
    "#  'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', \n",
    "#  'register_parameter', 'relu', 'requires_grad_', 'share_memory', \n",
    "#  'state_dict', 'to', 'train', 'training', 'type', 'zero_grad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.model_A(num_classes=10)\n",
    "# model.load_state_dict(torch.load(\"Task1_modelResnet_best_model.pkl\"))\n",
    "\n",
    "# from sys import path\n",
    "# path.append(r\"visualization_test\")\n",
    "# from misc_functions import preprocess_image, recreate_image, save_image\n",
    "# from torch.optim import Adam\n",
    "\n",
    "\n",
    "\n",
    "# if 1:\n",
    "#     name = \"test\"\n",
    "#     filter_pos = 5\n",
    "    \n",
    "#     print(type(model.conv1))\n",
    "#     print(type(model.bn1))\n",
    "#     print(type(model.relu))\n",
    "#     print(type(model.maxpool))\n",
    "#     print(type(model.layer1))\n",
    "#     print(type(model.layer2))\n",
    "#     print(type(model.layer3))\n",
    "#     print(type(model.layer4))\n",
    "            \n",
    "#     random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "#     # Process image and return variable\n",
    "#     processed_image = preprocess_image(random_image, False)\n",
    "#     # Define optimizer for the image\n",
    "#     optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "#     for i in range(1, 31):\n",
    "#         optimizer.zero_grad()\n",
    "#         x = processed_image\n",
    "        \n",
    "#         for sb in range(1):\n",
    "            \n",
    "#             x = model.conv1(x)\n",
    "#             x = model.bn1(x)\n",
    "#             x = model.relu(x)\n",
    "#             x = model.maxpool(x)\n",
    "#             x = model.layer1(x)\n",
    "            \n",
    "#         conv_output = x[0, filter_pos]\n",
    "#         # Loss function is the mean of the output of the selected layer/filter\n",
    "#         # We try to minimize the mean of the output of that specific filter\n",
    "#         loss = -torch.mean(conv_output)\n",
    "#         if i%5 == 0:\n",
    "#             print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "#         # Backward\n",
    "#         loss.backward()\n",
    "#         # Update image\n",
    "#         optimizer.step()\n",
    "#         # Recreate image\n",
    "#         created_image = recreate_image(processed_image)\n",
    "#         # Save image\n",
    "#         if i % 30 == 0:\n",
    "#             im_path = 'generated/layer_vis_l' + str(name) + \\\n",
    "#                 '_f' + str(filter_pos) + '_iter' + str(i) + '.jpg'\n",
    "#             save_image(created_image, im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15 Loss: -3.16\n",
      "Iteration: 30 Loss: -3.59\n",
      "Iteration: 15 Loss: -2.85\n",
      "Iteration: 30 Loss: -3.34\n",
      "Iteration: 15 Loss: -3.15\n",
      "Iteration: 30 Loss: -3.53\n",
      "Iteration: 15 Loss: -2.27\n",
      "Iteration: 30 Loss: -3.01\n",
      "Iteration: 15 Loss: -3.11\n",
      "Iteration: 30 Loss: -3.40\n"
     ]
    }
   ],
   "source": [
    "model = models.model_A(num_classes=10)\n",
    "model.load_state_dict(torch.load(\"Task1_modelResnet_best_model.pkl\"))\n",
    "\n",
    "from sys import path\n",
    "path.append(r\"visualization_test\")\n",
    "from misc_functions import preprocess_image, recreate_image, save_image\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "ddl = 10\n",
    "now = 0\n",
    "for inputs, labels in valid_loader:\n",
    "    now += 1\n",
    "    name = \"Afterlayer0_pic{0}\".format(str(now))\n",
    "    filter_pos = 5\n",
    "    \n",
    "    \n",
    "    random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            for c in range(3):\n",
    "                random_image[i,j,c] = inputs[0,c,i,j]\n",
    "    # Process image and return variable\n",
    "    processed_image = preprocess_image(random_image, False)\n",
    "    \n",
    "#     print(type(processed_image),type(inputs))\n",
    "#     print(processed_image.shape,inputs.shape)\n",
    "#     break\n",
    "#     processed_image = inputs.clone()\n",
    "    \n",
    "    # Define optimizer for the image\n",
    "    optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "    for i in range(1, 31):\n",
    "        optimizer.zero_grad()\n",
    "        x = processed_image\n",
    "        \n",
    "        for sb in range(1):\n",
    "            \n",
    "            x = model.conv1(x)\n",
    "            x = model.bn1(x)\n",
    "            x = model.relu(x)\n",
    "            x = model.maxpool(x)\n",
    "#             x = model.layer1(x)\n",
    "            \n",
    "        conv_output = x[0, filter_pos]\n",
    "        # Loss function is the mean of the output of the selected layer/filter\n",
    "        # We try to minimize the mean of the output of that specific filter\n",
    "        loss = -torch.mean(conv_output)\n",
    "        if i%15 == 0:\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Update image\n",
    "        optimizer.step()\n",
    "        # Recreate image\n",
    "        created_image = recreate_image(processed_image)\n",
    "        # Save image\n",
    "        if i % 30 == 0:\n",
    "            im_path = 'generated/layer_vis_' + str(name) + \\\n",
    "                '_f' + str(filter_pos) + '_iter' + str(i) + '.jpg'\n",
    "            save_image(created_image, im_path)\n",
    "            \n",
    "    ddl -= 1\n",
    "    if ddl<=0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15 Loss: -1.66\n",
      "Iteration: 30 Loss: -1.77\n",
      "Iteration: 15 Loss: -1.79\n",
      "Iteration: 30 Loss: -1.88\n",
      "Iteration: 15 Loss: -1.67\n",
      "Iteration: 30 Loss: -1.80\n",
      "Iteration: 15 Loss: -1.77\n",
      "Iteration: 30 Loss: -1.86\n",
      "Iteration: 15 Loss: -1.67\n",
      "Iteration: 30 Loss: -1.78\n"
     ]
    }
   ],
   "source": [
    "model = models.model_A(num_classes=10)\n",
    "model.load_state_dict(torch.load(\"Task1_modelResnet_best_model.pkl\"))\n",
    "\n",
    "from sys import path\n",
    "path.append(r\"visualization_test\")\n",
    "from misc_functions import preprocess_image, recreate_image, save_image\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "ddl = 10\n",
    "now = 0\n",
    "for inputs, labels in valid_loader:\n",
    "    now += 1\n",
    "    name = \"Afterlayer1_pic{0}\".format(str(now))\n",
    "    filter_pos = 5\n",
    "    \n",
    "    \n",
    "    random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            for c in range(3):\n",
    "                random_image[i,j,c] = inputs[0,c,i,j]\n",
    "    # Process image and return variable\n",
    "    processed_image = preprocess_image(random_image, False)\n",
    "    \n",
    "#     print(type(processed_image),type(inputs))\n",
    "#     print(processed_image.shape,inputs.shape)\n",
    "#     break\n",
    "#     processed_image = inputs.clone()\n",
    "    \n",
    "    # Define optimizer for the image\n",
    "    optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "    for i in range(1, 31):\n",
    "        optimizer.zero_grad()\n",
    "        x = processed_image\n",
    "        \n",
    "        for sb in range(1):\n",
    "            \n",
    "            x = model.conv1(x)\n",
    "            x = model.bn1(x)\n",
    "            x = model.relu(x)\n",
    "            x = model.maxpool(x)\n",
    "            x = model.layer1(x)\n",
    "            \n",
    "        conv_output = x[0, filter_pos]\n",
    "        # Loss function is the mean of the output of the selected layer/filter\n",
    "        # We try to minimize the mean of the output of that specific filter\n",
    "        loss = -torch.mean(conv_output)\n",
    "        if i%15 == 0:\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Update image\n",
    "        optimizer.step()\n",
    "        # Recreate image\n",
    "        created_image = recreate_image(processed_image)\n",
    "        # Save image\n",
    "        if i % 30 == 0:\n",
    "            im_path = 'generated/layer_vis_' + str(name) + \\\n",
    "                '_f' + str(filter_pos) + '_iter' + str(i) + '.jpg'\n",
    "            save_image(created_image, im_path)\n",
    "            \n",
    "    ddl -= 1\n",
    "    if ddl<=0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15 Loss: -2.16\n",
      "Iteration: 30 Loss: -2.33\n",
      "Iteration: 15 Loss: -2.31\n",
      "Iteration: 30 Loss: -2.41\n",
      "Iteration: 15 Loss: -2.15\n",
      "Iteration: 30 Loss: -2.32\n",
      "Iteration: 15 Loss: -2.20\n",
      "Iteration: 30 Loss: -2.35\n"
     ]
    }
   ],
   "source": [
    "model = models.model_A(num_classes=10)\n",
    "model.load_state_dict(torch.load(\"Task1_modelResnet_best_model.pkl\"))\n",
    "\n",
    "from sys import path\n",
    "path.append(r\"visualization_test\")\n",
    "from misc_functions import preprocess_image, recreate_image, save_image\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "ddl = 10\n",
    "now = 0\n",
    "for inputs, labels in valid_loader:\n",
    "    now += 1\n",
    "    name = \"Afterlayer2_pic{0}\".format(str(now))\n",
    "    filter_pos = 5\n",
    "    \n",
    "    \n",
    "    random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            for c in range(3):\n",
    "                random_image[i,j,c] = inputs[0,c,i,j]\n",
    "    # Process image and return variable\n",
    "    processed_image = preprocess_image(random_image, False)\n",
    "    \n",
    "#     print(type(processed_image),type(inputs))\n",
    "#     print(processed_image.shape,inputs.shape)\n",
    "#     break\n",
    "#     processed_image = inputs.clone()\n",
    "    \n",
    "    # Define optimizer for the image\n",
    "    optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "    for i in range(1, 31):\n",
    "        optimizer.zero_grad()\n",
    "        x = processed_image\n",
    "        \n",
    "        for sb in range(1):\n",
    "            \n",
    "            x = model.conv1(x)\n",
    "            x = model.bn1(x)\n",
    "            x = model.relu(x)\n",
    "            x = model.maxpool(x)\n",
    "            x = model.layer1(x)\n",
    "            x = model.layer2(x)\n",
    "            \n",
    "        conv_output = x[0, filter_pos]\n",
    "        # Loss function is the mean of the output of the selected layer/filter\n",
    "        # We try to minimize the mean of the output of that specific filter\n",
    "        loss = -torch.mean(conv_output)\n",
    "        if i%15 == 0:\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Update image\n",
    "        optimizer.step()\n",
    "        # Recreate image\n",
    "        created_image = recreate_image(processed_image)\n",
    "        # Save image\n",
    "        if i % 30 == 0:\n",
    "            im_path = 'generated/layer_vis_' + str(name) + \\\n",
    "                '_f' + str(filter_pos) + '_iter' + str(i) + '.jpg'\n",
    "            save_image(created_image, im_path)\n",
    "            \n",
    "    ddl -= 1\n",
    "    if ddl<=0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.model_A(num_classes=10)\n",
    "model.load_state_dict(torch.load(\"Task1_modelResnet_best_model.pkl\"))\n",
    "\n",
    "from sys import path\n",
    "path.append(r\"visualization_test\")\n",
    "from misc_functions import preprocess_image, recreate_image, save_image\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "ddl = 10\n",
    "now = 0\n",
    "for inputs, labels in valid_loader:\n",
    "    now += 1\n",
    "    name = \"Afterlayer3_pic{0}\".format(str(now))\n",
    "    filter_pos = 5\n",
    "    \n",
    "    \n",
    "    random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            for c in range(3):\n",
    "                random_image[i,j,c] = inputs[0,c,i,j]\n",
    "    # Process image and return variable\n",
    "    processed_image = preprocess_image(random_image, False)\n",
    "    \n",
    "#     print(type(processed_image),type(inputs))\n",
    "#     print(processed_image.shape,inputs.shape)\n",
    "#     break\n",
    "#     processed_image = inputs.clone()\n",
    "    \n",
    "    # Define optimizer for the image\n",
    "    optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "    for i in range(1, 31):\n",
    "        optimizer.zero_grad()\n",
    "        x = processed_image\n",
    "        \n",
    "        for sb in range(1):\n",
    "            \n",
    "            x = model.conv1(x)\n",
    "            x = model.bn1(x)\n",
    "            x = model.relu(x)\n",
    "            x = model.maxpool(x)\n",
    "            x = model.layer1(x)\n",
    "            x = model.layer2(x)\n",
    "            x = model.layer3(x)\n",
    "            \n",
    "        conv_output = x[0, filter_pos]\n",
    "        # Loss function is the mean of the output of the selected layer/filter\n",
    "        # We try to minimize the mean of the output of that specific filter\n",
    "        loss = -torch.mean(conv_output)\n",
    "        if i%15 == 0:\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Update image\n",
    "        optimizer.step()\n",
    "        # Recreate image\n",
    "        created_image = recreate_image(processed_image)\n",
    "        # Save image\n",
    "        if i % 30 == 0:\n",
    "            im_path = 'generated/layer_vis_' + str(name) + \\\n",
    "                '_f' + str(filter_pos) + '_iter' + str(i) + '.jpg'\n",
    "            save_image(created_image, im_path)\n",
    "            \n",
    "    ddl -= 1\n",
    "    if ddl<=0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.model_A(num_classes=10)\n",
    "model.load_state_dict(torch.load(\"Task1_modelResnet_best_model.pkl\"))\n",
    "\n",
    "from sys import path\n",
    "path.append(r\"visualization_test\")\n",
    "from misc_functions import preprocess_image, recreate_image, save_image\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "ddl = 10\n",
    "now = 0\n",
    "for inputs, labels in valid_loader:\n",
    "    now += 1\n",
    "    name = \"Afterlayer4_pic{0}\".format(str(now))\n",
    "    filter_pos = 5\n",
    "    \n",
    "    \n",
    "    random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            for c in range(3):\n",
    "                random_image[i,j,c] = inputs[0,c,i,j]\n",
    "    # Process image and return variable\n",
    "    processed_image = preprocess_image(random_image, False)\n",
    "    \n",
    "#     print(type(processed_image),type(inputs))\n",
    "#     print(processed_image.shape,inputs.shape)\n",
    "#     break\n",
    "#     processed_image = inputs.clone()\n",
    "    \n",
    "    # Define optimizer for the image\n",
    "    optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "    for i in range(1, 31):\n",
    "        optimizer.zero_grad()\n",
    "        x = processed_image\n",
    "        \n",
    "        for sb in range(1):\n",
    "            \n",
    "            x = model.conv1(x)\n",
    "            x = model.bn1(x)\n",
    "            x = model.relu(x)\n",
    "            x = model.maxpool(x)\n",
    "            x = model.layer1(x)\n",
    "            x = model.layer2(x)\n",
    "            x = model.layer3(x)\n",
    "            x = model.layer4(x)\n",
    "            \n",
    "        conv_output = x[0, filter_pos]\n",
    "        # Loss function is the mean of the output of the selected layer/filter\n",
    "        # We try to minimize the mean of the output of that specific filter\n",
    "        loss = -torch.mean(conv_output)\n",
    "        if i%15 == 0:\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Update image\n",
    "        optimizer.step()\n",
    "        # Recreate image\n",
    "        created_image = recreate_image(processed_image)\n",
    "        # Save image\n",
    "        if i % 30 == 0:\n",
    "            im_path = 'generated/layer_vis_' + str(name) + \\\n",
    "                '_f' + str(filter_pos) + '_iter' + str(i) + '.jpg'\n",
    "            save_image(created_image, im_path)\n",
    "            \n",
    "    ddl -= 1\n",
    "    if ddl<=0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <class 'torch.nn.modules.container.Sequential'>\n",
    "#   0 ResNet(\n",
    "#   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "#   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#   (relu): ReLU(inplace=True)\n",
    "#   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "#   (layer1): Sequential(\n",
    "#     (0): Bottleneck(\n",
    "#       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#       (downsample): Sequential(\n",
    "#         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       )\n",
    "#     )\n",
    "#     (1): Bottleneck(\n",
    "#       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#     (2): Bottleneck(\n",
    "#       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#   )\n",
    "#   (layer2): Sequential(\n",
    "#     (0): Bottleneck(\n",
    "#       (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#       (downsample): Sequential(\n",
    "#         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "#         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       )\n",
    "#     )\n",
    "#     (1): Bottleneck(\n",
    "#       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#     (2): Bottleneck(\n",
    "#       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#     (3): Bottleneck(\n",
    "#       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#   )\n",
    "#   (layer3): Sequential(\n",
    "#     (0): Bottleneck(\n",
    "#       (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#       (downsample): Sequential(\n",
    "#         (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "#         (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       )\n",
    "#     )\n",
    "#     (1): Bottleneck(\n",
    "#       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#     (2): Bottleneck(\n",
    "#       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#     (3): Bottleneck(\n",
    "#       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#     (4): Bottleneck(\n",
    "#       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#     (5): Bottleneck(\n",
    "#       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#   )\n",
    "#   (layer4): Sequential(\n",
    "#     (0): Bottleneck(\n",
    "#       (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#       (downsample): Sequential(\n",
    "#         (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
    "#         (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       )\n",
    "#     )\n",
    "#     (1): Bottleneck(\n",
    "#       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#     (2): Bottleneck(\n",
    "#       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "#       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#       (relu): ReLU(inplace=True)\n",
    "#     )\n",
    "#   )\n",
    "#   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "#   (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
